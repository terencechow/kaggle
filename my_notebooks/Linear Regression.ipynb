{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "logs_dir = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [6.2, 9.5, 10.5, 7.7, 8.6, 34.1, 11, 6.9, 7.3, 15.1, 29.1, 2.2, 5.7, 2,\n",
    "     2.5, 4, 5.4, 2.2, 7.2, 15.1, 16.5, 18.4, 36.2, 39.7, 18.5, 23.3, 12.2,\n",
    "     5.6, 21.8, 21.6, 9, 3.6, 5, 28.6, 17.4, 11.3, 3.4, 11.9, 10.5, 10.7, 10.8,\n",
    "     4.8]\n",
    "y = [29, 44, 36, 37, 53, 68, 75, 18, 31, 25, 34, 14, 11, 11, 22, 16, 27, 9, 29,\n",
    "     30, 40, 32, 41, 147, 22, 29, 46, 23, 4, 31, 39, 15, 32, 27, 32, 34, 17,\n",
    "     46, 42, 43, 34, 19]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "w = tf.Variable(0.0, name='weights')\n",
    "b = tf.Variable(0.0, name='bias')\n",
    "\n",
    "Y_predicted = X * w + b\n",
    "loss = tf.square(Y - Y_predicted, name='loss')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=.001).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished. Average Loss: 2069.6319333978354\n",
      "Epoch 1 finished. Average Loss: 2117.0123581953535\n",
      "Epoch 2 finished. Average Loss: 2092.302723001866\n",
      "Epoch 3 finished. Average Loss: 2068.5080461938464\n",
      "Epoch 4 finished. Average Loss: 2045.591184088162\n",
      "Epoch 5 finished. Average Loss: 2023.5146448101316\n",
      "Epoch 6 finished. Average Loss: 2002.2447619835536\n",
      "Epoch 7 finished. Average Loss: 1981.748338803649\n",
      "Epoch 8 finished. Average Loss: 1961.9944411260742\n",
      "Epoch 9 finished. Average Loss: 1942.9520116143283\n",
      "Epoch 10 finished. Average Loss: 1924.5930823644712\n",
      "Epoch 11 finished. Average Loss: 1906.8898800636332\n",
      "Epoch 12 finished. Average Loss: 1889.8164505837929\n",
      "Epoch 13 finished. Average Loss: 1873.347133841543\n",
      "Epoch 14 finished. Average Loss: 1857.4588400604468\n",
      "Epoch 15 finished. Average Loss: 1842.1278742424079\n",
      "Epoch 16 finished. Average Loss: 1827.332495119955\n",
      "Epoch 17 finished. Average Loss: 1813.0520579712022\n",
      "Epoch 18 finished. Average Loss: 1799.2660847636982\n",
      "Epoch 19 finished. Average Loss: 1785.9562132299961\n",
      "Epoch 20 finished. Average Loss: 1773.1024853109072\n",
      "Epoch 21 finished. Average Loss: 1760.689129482884\n",
      "Epoch 22 finished. Average Loss: 1748.6984157081515\n",
      "Epoch 23 finished. Average Loss: 1737.1138680398553\n",
      "Epoch 24 finished. Average Loss: 1725.920873066732\n",
      "Epoch 25 finished. Average Loss: 1715.1046249579008\n",
      "Epoch 26 finished. Average Loss: 1704.6500954309377\n",
      "Epoch 27 finished. Average Loss: 1694.5447134910141\n",
      "Epoch 28 finished. Average Loss: 1684.7746311347667\n",
      "Epoch 29 finished. Average Loss: 1675.328450968245\n",
      "Epoch 30 finished. Average Loss: 1666.1935385839038\n",
      "Epoch 31 finished. Average Loss: 1657.3584002084322\n",
      "Epoch 32 finished. Average Loss: 1648.8122658529207\n",
      "Epoch 33 finished. Average Loss: 1640.5440742547091\n",
      "Epoch 34 finished. Average Loss: 1632.5446836102221\n",
      "Epoch 35 finished. Average Loss: 1624.8043315147183\n",
      "Epoch 36 finished. Average Loss: 1617.3126799958602\n",
      "Epoch 37 finished. Average Loss: 1610.0622532456405\n",
      "Epoch 38 finished. Average Loss: 1603.0433557207386\n",
      "Epoch 39 finished. Average Loss: 1596.2479176106197\n",
      "Epoch 40 finished. Average Loss: 1589.668056331575\n",
      "Epoch 41 finished. Average Loss: 1583.2965242617897\n",
      "Epoch 42 finished. Average Loss: 1577.126371285745\n",
      "Epoch 43 finished. Average Loss: 1571.1501190634\n",
      "Epoch 44 finished. Average Loss: 1565.360979151513\n",
      "Epoch 45 finished. Average Loss: 1559.7523780798629\n",
      "Epoch 46 finished. Average Loss: 1554.3184364555138\n",
      "Epoch 47 finished. Average Loss: 1549.0529469620615\n",
      "Epoch 48 finished. Average Loss: 1543.950059985476\n",
      "Epoch 49 finished. Average Loss: 1539.0050282141283\n",
      "Epoch 50 finished. Average Loss: 1534.211797797609\n",
      "Epoch 51 finished. Average Loss: 1529.56534988646\n",
      "Epoch 52 finished. Average Loss: 1525.0607591186251\n",
      "Epoch 53 finished. Average Loss: 1520.6934648507852\n",
      "Epoch 54 finished. Average Loss: 1516.4585935090713\n",
      "Epoch 55 finished. Average Loss: 1512.3524023861364\n",
      "Epoch 56 finished. Average Loss: 1508.3695780125756\n",
      "Epoch 57 finished. Average Loss: 1504.5066588066873\n",
      "Epoch 58 finished. Average Loss: 1500.7606269073274\n",
      "Epoch 59 finished. Average Loss: 1497.126336559476\n",
      "Epoch 60 finished. Average Loss: 1493.600210891061\n",
      "Epoch 61 finished. Average Loss: 1490.1794991287668\n",
      "Epoch 62 finished. Average Loss: 1486.8605145300749\n",
      "Epoch 63 finished. Average Loss: 1483.639419928193\n",
      "Epoch 64 finished. Average Loss: 1480.5144186365596\n",
      "Epoch 65 finished. Average Loss: 1477.4811065652452\n",
      "Epoch 66 finished. Average Loss: 1474.5376660533782\n",
      "Epoch 67 finished. Average Loss: 1471.6799176652871\n",
      "Epoch 68 finished. Average Loss: 1468.9063155567717\n",
      "Epoch 69 finished. Average Loss: 1466.2136880280007\n",
      "Epoch 70 finished. Average Loss: 1463.5996563179153\n",
      "Epoch 71 finished. Average Loss: 1461.0614086978492\n",
      "Epoch 72 finished. Average Loss: 1458.597208841216\n",
      "Epoch 73 finished. Average Loss: 1456.2043069711044\n",
      "Epoch 74 finished. Average Loss: 1453.8807724802089\n",
      "Epoch 75 finished. Average Loss: 1451.6242183893032\n",
      "Epoch 76 finished. Average Loss: 1449.432753210976\n",
      "Epoch 77 finished. Average Loss: 1447.3042320180018\n",
      "Epoch 78 finished. Average Loss: 1445.237068621615\n",
      "Epoch 79 finished. Average Loss: 1443.228872676177\n",
      "Epoch 80 finished. Average Loss: 1441.2782130186733\n",
      "Epoch 81 finished. Average Loss: 1439.3831422174615\n",
      "Epoch 82 finished. Average Loss: 1437.542224922173\n",
      "Epoch 83 finished. Average Loss: 1435.7540219968096\n",
      "Epoch 84 finished. Average Loss: 1434.0160684508405\n",
      "Epoch 85 finished. Average Loss: 1432.3276573866606\n",
      "Epoch 86 finished. Average Loss: 1430.687153330871\n",
      "Epoch 87 finished. Average Loss: 1429.093016880254\n",
      "Epoch 88 finished. Average Loss: 1427.543719962062\n",
      "Epoch 89 finished. Average Loss: 1426.038033108981\n",
      "Epoch 90 finished. Average Loss: 1424.5748210840281\n",
      "Epoch 91 finished. Average Loss: 1423.1531702368743\n",
      "Epoch 92 finished. Average Loss: 1421.771026852585\n",
      "Epoch 93 finished. Average Loss: 1420.4274983895677\n",
      "Epoch 94 finished. Average Loss: 1419.121967994741\n",
      "Epoch 95 finished. Average Loss: 1417.85251878131\n",
      "Epoch 96 finished. Average Loss: 1416.618930517208\n",
      "Epoch 97 finished. Average Loss: 1415.4196022436731\n",
      "Epoch 98 finished. Average Loss: 1414.2534379121803\n",
      "Epoch 99 finished. Average Loss: 1413.1202843011845\n",
      "Final weights: 1.7183812856674194\n",
      "Final bias: 15.789156913757324\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # writer = tf.summary.FileWriter(logs_dir, sess.graph)\n",
    "    sess.run(init)\n",
    "    for i in range(100):\n",
    "        total_loss = 0\n",
    "        for j in range(len(x)):\n",
    "            _, current_loss = sess.run([optimizer, loss], feed_dict={X: x[j], Y: y[j]})\n",
    "            total_loss += current_loss\n",
    "        print(\"Epoch {} finished. Average Loss: {}\".format(i,total_loss / len(x) ))\n",
    "    w_value, b_value = sess.run([w, b])\n",
    "    print(\"Final weights: {}\".format(w_value))\n",
    "    print(\"Final bias: {}\".format(b_value))\n",
    "    # writer.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-03d0f731c5c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_fit_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# X_input = np.linspace(-1, 1, 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Y_input = X_input * 3 + np.random.randn(X_input.shape[0]) * 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float32' object cannot be interpreted as an integer"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqXAGvSQVzqCXpML9LwKf4AcxEYjZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e90edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_fit_x = [0, 40]\n",
    "best_fit_y = [b_value, 40 * w_value + b_value]\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.plot(x, x * w_value + b_value)\n",
    "# X_input = np.linspace(-1, 1, 100)\n",
    "# Y_input = X_input * 3 + np.random.randn(X_input.shape[0]) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
